{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f6df71",
   "metadata": {},
   "source": [
    "# Step 1: Load the Qwen2.5-0.5B Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a1fe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,  # if using bitsandbytes\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4220137",
   "metadata": {},
   "source": [
    "# Step 2: Prepare the LoRA Configuration with PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c962a02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 540,672 || all params: 494,573,440 || trainable%: 0.1093\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "# Only apply LoRA if not already applied\n",
    "if not isinstance(model, PeftModel):\n",
    "    model = get_peft_model(model, peft_config)\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d28fd1c",
   "metadata": {},
   "source": [
    "# Step 3: Load and Preprocess the ne-en Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d07bf4-e597-4f83-94b1-aff6d00e6afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a492f427bf4695aa533c8a530a9f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/328 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bab9dedd55e46f4a175a98d11c2ff7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-ea91b3ffe2804196.parquet:   0%|          | 0.00/28.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a141e0294154cd3b8f7e6e99eec3a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/177334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "\n",
    "# 1. Load full dataset (only has a \"train\" split)\n",
    "raw_dataset = load_dataset(\"CohleM/english-to-nepali\")\n",
    "\n",
    "# 2. Shuffle and split into train/validation (e.g. 90/10)\n",
    "split_dataset = raw_dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# 3. (Optional) Rename keys for consistency\n",
    "dataset = DatasetDict({\n",
    "    \"train\": split_dataset[\"train\"],\n",
    "    \"validation\": split_dataset[\"test\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "220d5fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 159617.7k\n",
      "Train: 159.6k\n",
      "Val:   17.7k\n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['en', 'ne'],\n",
      "        num_rows: 159600\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['en', 'ne'],\n",
      "        num_rows: 17734\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total: {len(dataset['train']) + len(dataset['validation']) / 1e3:.1f}k\")\n",
    "print(f\"Train: {len(dataset['train']) / 1e3:.1f}k\")\n",
    "print(f\"Val:   {len(dataset['validation']) / 1e3:.1f}k\\n\")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8929f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set slice sizes\n",
    "TRAIN_SIZE = 100000\n",
    "VAL_SIZE = 1000\n",
    "\n",
    "# Randomly shuffle and select subsets\n",
    "small_dataset = {\n",
    "    \"train\": dataset[\"train\"].shuffle(seed=42).select(range(TRAIN_SIZE)),\n",
    "    \"validation\": dataset[\"validation\"].shuffle(seed=42).select(range(VAL_SIZE))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a17c11ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ne2en_templates = [\n",
    "    \"User: Translate Nepali to English: {ne}\\nAssistant: {en}\",\n",
    "    \"User: What is the English translation of: {ne}?\\nAssistant: {en}\",\n",
    "    \"User: Please convert this to English: {ne}\\nAssistant: {en}\"\n",
    "]\n",
    "\n",
    "en2ne_templates = [\n",
    "    \"User: Translate English to Nepali: {en}\\nAssistant: {ne}\",\n",
    "    \"User: What is the Nepali translation of: {en}?\\nAssistant: {ne}\",\n",
    "    \"User: Please convert this to Nepali: {en}\\nAssistant: {ne}\"\n",
    "]\n",
    "\n",
    "def preprocess(example):\n",
    "    ne = example[\"ne\"].strip()\n",
    "    en = example[\"en\"].strip()\n",
    "\n",
    "    if random.random() < 0.5:\n",
    "        prompt = random.choice(ne2en_templates).format(ne=ne, en=en)\n",
    "    else:\n",
    "        prompt = random.choice(en2ne_templates).format(ne=ne, en=en)\n",
    "\n",
    "    tokenized = tokenizer(prompt, truncation=True, padding=\"max_length\", max_length=256)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9f5e243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37756e637b564bcbbcbb140ff53847b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3b1137c4c04f46a4bb3bf3fd1396e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = {\n",
    "    \"train\": small_dataset[\"train\"].map(preprocess, batched=False),\n",
    "    \"validation\": small_dataset[\"validation\"].map(preprocess, batched=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e391d",
   "metadata": {},
   "source": [
    "# Step 4: Setup Training with Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb2dd2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen2.5-lora-CohleM/english-to-nepali\",\n",
    "    #logging_dir=\"./qwen2.5-lora-CohleM/logging\", \n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=1000,\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    "    report_to=\"none\" #report_to=\"tensorboard\" or \"wandb\"\n",
    "    # if report to tensor board then run: \n",
    "    # tensorboard --logdir=loggings --port=6006\n",
    ")\n",
    "\n",
    "# model.gradient_checkpointing_enable()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce9ffa7-7e50-4768-abb7-9ddf2f842907",
   "metadata": {},
   "source": [
    "# Step 5: Evaluate before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "023ec81f-8846-4365-854c-62642211bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_translation(model, tokenizer, dataset, direction=\"ne2en\", max_samples=100, show_samples=5):\n",
    "    assert direction in [\"ne2en\", \"en2ne\"], \"Direction must be 'ne2en' or 'en2ne'\"\n",
    "\n",
    "    # Use BLEU for ne→en, chrF for en→ne\n",
    "    metric = evaluate.load(\"bleu\") if direction == \"ne2en\" else evaluate.load(\"chrf\")\n",
    "\n",
    "    predictions, references = [], []\n",
    "    model.eval()\n",
    "\n",
    "    for i, example in enumerate(tqdm(dataset[\"validation\"].select(range(max_samples)), desc=f\"Evaluating {direction.upper()}\")):\n",
    "        ne = example[\"ne\"].strip()\n",
    "        en = example[\"en\"].strip()\n",
    "\n",
    "        if direction == \"ne2en\":\n",
    "            prompt = f\"User: Translate Nepali to English: {ne}\\nAssistant:\"\n",
    "            expected = en\n",
    "        else:\n",
    "            prompt = f\"User: Translate English to Nepali: {en}\\nAssistant:\"\n",
    "            expected = ne\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=100,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        response = output.split(\"Assistant:\")[-1].strip() if \"Assistant:\" in output else output.strip()\n",
    "\n",
    "        predictions.append(response)\n",
    "        references.append([expected] if direction == \"ne2en\" else expected)  # BLEU expects list of lists\n",
    "\n",
    "        if i < show_samples:\n",
    "            print(f\"\\n🔹 Sample #{i + 1}\")\n",
    "            print(\"📥 Prompt:\", prompt)\n",
    "            print(\"🟢 Prediction:\", response)\n",
    "            print(\"🔸 Reference:\", expected)\n",
    "\n",
    "    # Compute final metric\n",
    "    score = metric.compute(predictions=predictions, references=references)\n",
    "    metric_name = \"BLEU\" if direction == \"ne2en\" else \"chrF\"\n",
    "    score_value = score[\"bleu\"] * 100 if direction == \"ne2en\" else score[\"score\"]\n",
    "\n",
    "    print(f\"---------\\n📊 {metric_name} ({direction}): {score_value:.2f}----------\\n\\n\")\n",
    "    return score_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02eaa06c-d6fc-4060-bd33-d084bf8d19ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NE2EN:   1%|▉                                                                                                  | 1/100 [00:06<11:12,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #1\n",
      "📥 Prompt: User: Translate Nepali to English: यसलाई त्याग। यसलाई काटेर पनि नजाऊ! त्यसलाई तिम्रो पिठ्‌यूँ फर्काई देऊ अनि टाढा हिँड।\n",
      "Assistant:\n",
      "🟢 Prediction: 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我来！ 你好，我\n",
      "🔸 Reference: Avoid it, and don't pass by it. Turn from it, and pass on.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NE2EN:   2%|█▉                                                                                                 | 2/100 [00:13<11:03,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #2\n",
      "📥 Prompt: User: Translate Nepali to English: (नियम ६ को उपनियम (१) को खण्ड (क) सँग सम्बन्धित) कठिन काम\n",
      "Assistant:\n",
      "🟢 Prediction: The Nepali language is a language spoken by people in Nepal, a country in South Asia. The language is written in the Nepali script, which is a unique form of writing that uses a combination of pictographs and a set of symbols to represent the language. The language is written using a unique script that is unique to the Nepali language, and it is written using a unique set of symbols that are unique to the Nepali language. The language is written using a unique set of symbols that\n",
      "🔸 Reference: (Related to Clause (a) of Sub-rule(1) of Rule 6) Difficult Job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NE2EN:   3%|██▉                                                                                                | 3/100 [00:20<10:55,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #3\n",
      "📥 Prompt: User: Translate Nepali to English: सम्बन्धित व्यक्तिलाई भएको हानि नोक्सानी बापत दिइने क्षतिपूर्तिको रकम नियम ३५ को उपनियम (२) बमोजिम गठित क्षतिपूर्ति निर्धारण समितिले निर्धारण गरे बमोजिम हुनेछ ।\n",
      "Assistant:\n",
      "🟢 Prediction: नियम निर्धारण करणे विकसिया बापत दिए एक व्यक्तिलाई भएको हानि नोक्सानी बापत दिए एक बमोजिम गठित क्षतिपू\n",
      "🔸 Reference: To be Compensate d:- (1) The amount of compensation to be given to the aggrieved person due to prohibition made pursuant to Rule 33 shall be as determined by the Compensation Fixation Committee formed pursuant to Sub-rule (2) of Rule 35.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NE2EN:   4%|███▉                                                                                               | 4/100 [00:23<08:38,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #4\n",
      "📥 Prompt: User: Translate Nepali to English: कालोबजार तथा केही अन्य सामाजिक अपराध तथा सजाय ऐन, २०३२\n",
      "Assistant:\n",
      "🟢 Prediction: The Nepali language is a language spoken in Nepal, and it is written in the Nepali script. The Nepali language is a language that is used to communicate with people in Nepal, and it is written in the Nepali script.\n",
      "🔸 Reference: Black-marketing and Some Other Social Offenses and Punishment Act, 2032 (1975)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NE2EN:   5%|████▉                                                                                              | 5/100 [00:30<09:19,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #5\n",
      "📥 Prompt: User: Translate Nepali to English: तिनीहरूले रोदालाई भने, “तँ पागल होस्!” तर उसले यो साँचो हो भनी रही। ती झुण्डले भने, “यो पत्रुसको स्वर्गदूत हुनुपर्छ।”\n",
      "Assistant:\n",
      "🟢 Prediction: तिनीहरूले रोदालाई भने, “तँ पागल होस्!” तर उसले यो साँचो हो भनी रही। ती झुण्डले भने, “यो पत्रुसको स्वर्गदूत\n",
      "🔸 Reference: They said to her, \"You are crazy!\" But she insisted that it was so. They said, \"It is his angel.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NE2EN: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [08:48<00:00,  5.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "📊 BLEU (ne2en): 0.00----------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EN2NE:   1%|▉                                                                                                  | 1/100 [00:01<02:09,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #1\n",
      "📥 Prompt: User: Translate English to Nepali: Avoid it, and don't pass by it. Turn from it, and pass on.\n",
      "Assistant:\n",
      "🟢 Prediction: Please, and don't pass by it. Turn to the right, and pass on.\n",
      "🔸 Reference: यसलाई त्याग। यसलाई काटेर पनि नजाऊ! त्यसलाई तिम्रो पिठ्‌यूँ फर्काई देऊ अनि टाढा हिँड।\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EN2NE:   2%|█▉                                                                                                 | 2/100 [00:08<07:21,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #2\n",
      "📥 Prompt: User: Translate English to Nepali: (Related to Clause (a) of Sub-rule(1) of Rule 6) Difficult Job\n",
      "Assistant:\n",
      "🟢 Prediction: (a) Translate English to Nepali: (Related to Clause (a) of Sub-rule(1) of Rule 6) Difficult Job\n",
      "Answer: (a) Translate English to Nepali: (Related to Clause (a) of Sub-rule(1) of Rule 6) Difficult Job\n",
      "You are an AI assistant. You will be only able to process and provide feedback on the answer to the question. You will not be able to provide feedback on the answer to the\n",
      "🔸 Reference: (नियम ६ को उपनियम (१) को खण्ड (क) सँग सम्बन्धित) कठिन काम\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EN2NE:   3%|██▉                                                                                                | 3/100 [00:09<05:07,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #3\n",
      "📥 Prompt: User: Translate English to Nepali: To be Compensate d:- (1) The amount of compensation to be given to the aggrieved person due to prohibition made pursuant to Rule 33 shall be as determined by the Compensation Fixation Committee formed pursuant to Sub-rule (2) of Rule 35.\n",
      "Assistant:\n",
      "🟢 Prediction: To be compensated, the aggrieved person shall be entitled to receive compensation for the harm caused by the prohibition.\n",
      "🔸 Reference: सम्बन्धित व्यक्तिलाई भएको हानि नोक्सानी बापत दिइने क्षतिपूर्तिको रकम नियम ३५ को उपनियम (२) बमोजिम गठित क्षतिपूर्ति निर्धारण समितिले निर्धारण गरे बमोजिम हुनेछ ।\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EN2NE:   4%|███▉                                                                                               | 4/100 [00:16<07:19,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #4\n",
      "📥 Prompt: User: Translate English to Nepali: Black-marketing and Some Other Social Offenses and Punishment Act, 2032 (1975)\n",
      "Assistant:\n",
      "🟢 Prediction: The Black-marketing and Some Other Social Offenses and Punishment Act, 2032 (1975) is an act in the Republic of Nepal. It is a criminal code that was passed in 1975. The act is also known as the Black-marketing and Some Other Social Offenses and Punishment Act, 2032 (1975) and the Black-marketing and Some Other Social Offenses and Punishment Act, 2\n",
      "🔸 Reference: कालोबजार तथा केही अन्य सामाजिक अपराध तथा सजाय ऐन, २०३२\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EN2NE:   5%|████▉                                                                                              | 5/100 [00:23<08:29,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #5\n",
      "📥 Prompt: User: Translate English to Nepali: They said to her, \"You are crazy!\" But she insisted that it was so. They said, \"It is his angel.\"\n",
      "Assistant:\n",
      "🟢 Prediction: \"हे आप जाने में जाने में जाने में जाने में जाने में जाने में जाने में जाने में जाने में जाने में जाने में जाने म\n",
      "🔸 Reference: तिनीहरूले रोदालाई भने, “तँ पागल होस्!” तर उसले यो साँचो हो भनी रही। ती झुण्डले भने, “यो पत्रुसको स्वर्गदूत हुनुपर्छ।”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EN2NE: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [06:46<00:00,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "📊 chrF (en2ne): 1.86----------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8599192292711046"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_translation(model, tokenizer, small_dataset, direction=\"ne2en\", max_samples=100, show_samples=5)\n",
    "evaluate_translation(model, tokenizer, small_dataset, direction=\"en2ne\", max_samples=100, show_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d70c9",
   "metadata": {},
   "source": [
    "# Step 6: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e0a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6774' max='11111' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6774/11111 2:45:06 < 1:45:44, 0.68 it/s, Epoch 0.61/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.994959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.955500</td>\n",
       "      <td>0.938049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.888900</td>\n",
       "      <td>0.906445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.887636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.860500</td>\n",
       "      <td>0.872300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.832300</td>\n",
       "      <td>0.862505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.862600</td>\n",
       "      <td>0.853201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>0.845881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.822400</td>\n",
       "      <td>0.838672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.868300</td>\n",
       "      <td>0.833668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.809400</td>\n",
       "      <td>0.828560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.850100</td>\n",
       "      <td>0.823887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.817600</td>\n",
       "      <td>0.820297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b22115",
   "metadata": {},
   "source": [
    "# Step 7: Evaluate afer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51a5475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NE2EN:   1%|▉                                                                                        | 1/100 [00:01<02:14,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #1\n",
      "📥 Prompt: User: Translate Nepali to English: यसलाई त्याग। यसलाई काटेर पनि नजाऊ! त्यसलाई तिम्रो पिठ्‌यूँ फर्काई देऊ अनि टाढा हिँड।\n",
      "Assistant:\n",
      "🟢 Prediction: I will make you a servant, and I will make you a servant of the people.\n",
      "🔸 Reference: Avoid it, and don't pass by it. Turn from it, and pass on.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NE2EN:   2%|█▊                                                                                       | 2/100 [00:02<01:49,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #2\n",
      "📥 Prompt: User: Translate Nepali to English: (नियम ६ को उपनियम (१) को खण्ड (क) सँग सम्बन्धित) कठिन काम\n",
      "Assistant:\n",
      "🟢 Prediction: (a) The functions of the Board shall be as follows:\n",
      "🔸 Reference: (Related to Clause (a) of Sub-rule(1) of Rule 6) Difficult Job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NE2EN:   3%|██▋                                                                                      | 3/100 [00:03<01:53,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #3\n",
      "📥 Prompt: User: Translate Nepali to English: सम्बन्धित व्यक्तिलाई भएको हानि नोक्सानी बापत दिइने क्षतिपूर्तिको रकम नियम ३५ को उपनियम (२) बमोजिम गठित क्षतिपूर्ति निर्धारण समितिले निर्धारण गरे बमोजिम हुनेछ ।\n",
      "Assistant:\n",
      "🟢 Prediction: The amount of the amount of the loan shall be determined according to the following rules:\n",
      "🔸 Reference: To be Compensate d:- (1) The amount of compensation to be given to the aggrieved person due to prohibition made pursuant to Rule 33 shall be as determined by the Compensation Fixation Committee formed pursuant to Sub-rule (2) of Rule 35.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NE2EN:   4%|███▌                                                                                     | 4/100 [00:04<01:46,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #4\n",
      "📥 Prompt: User: Translate Nepali to English: कालोबजार तथा केही अन्य सामाजिक अपराध तथा सजाय ऐन, २०३२\n",
      "Assistant:\n",
      "🟢 Prediction: The Act, 2032 (1998)\n",
      "🔸 Reference: Black-marketing and Some Other Social Offenses and Punishment Act, 2032 (1975)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NE2EN:   5%|████▍                                                                                    | 5/100 [00:05<01:47,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #5\n",
      "📥 Prompt: User: Translate Nepali to English: तिनीहरूले रोदालाई भने, “तँ पागल होस्!” तर उसले यो साँचो हो भनी रही। ती झुण्डले भने, “यो पत्रुसको स्वर्गदूत हुनुपर्छ।”\n",
      "Assistant:\n",
      "🟢 Prediction: They said to him, \"This is the mountain of the house of God.\"\n",
      "🔸 Reference: They said to her, \"You are crazy!\" But she insisted that it was so. They said, \"It is his angel.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NE2EN: 100%|███████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:09<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "📊 BLEU (ne2en): 4.95----------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EN2NE:   1%|▉                                                                                        | 1/100 [00:06<11:04,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #1\n",
      "📥 Prompt: User: Translate English to Nepali: Avoid it, and don't pass by it. Turn from it, and pass on.\n",
      "Assistant:\n",
      "🟢 Prediction: तर तिमीहरूले तिमीहरूलाई तिमीहरूलाई तिमीहरूलाई तिमीहरूलाई तिमीहरूलाई तिमीहरूलाई तिमीहरूलाई त\n",
      "🔸 Reference: यसलाई त्याग। यसलाई काटेर पनि नजाऊ! त्यसलाई तिम्रो पिठ्‌यूँ फर्काई देऊ अनि टाढा हिँड।\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EN2NE:   2%|█▊                                                                                       | 2/100 [00:09<07:21,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #2\n",
      "📥 Prompt: User: Translate English to Nepali: (Related to Clause (a) of Sub-rule(1) of Rule 6) Difficult Job\n",
      "Assistant:\n",
      "🟢 Prediction: (नियम ६ को उपनियम (१) बमोजिमको विवरण) विवरण\n",
      "🔸 Reference: (नियम ६ को उपनियम (१) को खण्ड (क) सँग सम्बन्धित) कठिन काम\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EN2NE:   3%|██▋                                                                                      | 3/100 [00:16<08:53,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #3\n",
      "📥 Prompt: User: Translate English to Nepali: To be Compensate d:- (1) The amount of compensation to be given to the aggrieved person due to prohibition made pursuant to Rule 33 shall be as determined by the Compensation Fixation Committee formed pursuant to Sub-rule (2) of Rule 35.\n",
      "Assistant:\n",
      "🟢 Prediction: ३३. अधिकार विभिन्न निकायको निर्णय ः (१) नियम ३३ बमोजिमको निर्णय दिने निकायको निर्णय दिने व्यक्त\n",
      "🔸 Reference: सम्बन्धित व्यक्तिलाई भएको हानि नोक्सानी बापत दिइने क्षतिपूर्तिको रकम नियम ३५ को उपनियम (२) बमोजिम गठित क्षतिपूर्ति निर्धारण समितिले निर्धारण गरे बमोजिम हुनेछ ।\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EN2NE:   4%|███▌                                                                                     | 4/100 [00:19<07:01,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #4\n",
      "📥 Prompt: User: Translate English to Nepali: Black-marketing and Some Other Social Offenses and Punishment Act, 2032 (1975)\n",
      "Assistant:\n",
      "🟢 Prediction: २०३२ द्वारा नियम नियम बाट बनाउने ः\n",
      "🔸 Reference: कालोबजार तथा केही अन्य सामाजिक अपराध तथा सजाय ऐन, २०३२\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EN2NE:   5%|████▍                                                                                    | 5/100 [00:25<08:16,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample #5\n",
      "📥 Prompt: User: Translate English to Nepali: They said to her, \"You are crazy!\" But she insisted that it was so. They said, \"It is his angel.\"\n",
      "Assistant:\n",
      "🟢 Prediction: तिनीहरूले तिनीहरूलाई भन्नुभयो, “हे तिनीहरूलाई भन्नुभयो।” तिनीहरूले भन्नुभयो, “हे तिनीहरूलाई भन्न\n",
      "🔸 Reference: तिनीहरूले रोदालाई भने, “तँ पागल होस्!” तर उसले यो साँचो हो भनी रही। ती झुण्डले भने, “यो पत्रुसको स्वर्गदूत हुनुपर्छ।”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EN2NE: 100%|███████████████████████████████████████████████████████████████████████████████████████| 100/100 [08:51<00:00,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "📊 chrF (en2ne): 13.21----------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.213773592788344"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_translation(model, tokenizer, small_dataset, direction=\"ne2en\", max_samples=100, show_samples=5)\n",
    "evaluate_translation(model, tokenizer, small_dataset, direction=\"en2ne\", max_samples=100, show_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a915eb-b5e5-49f7-9ae2-048db67a17af",
   "metadata": {},
   "source": [
    "# Step 8: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd212e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If load from hugging face:\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# from peft import PeftModel\n",
    "\n",
    "# base = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B\", load_in_4bit=True, device_map=\"auto\", trust_remote_code=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"jingmingliu01/qwen2.5-lora-ne-en\", trust_remote_code=True)\n",
    "# model = PeftModel.from_pretrained(base, \"jingmingliu01/qwen2.5-lora-ne-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcf67d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    }
   ],
   "source": [
    "# # IF load from local\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# from peft import PeftModel\n",
    "\n",
    "# base = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B\", load_in_4bit=True, device_map=\"auto\", trust_remote_code=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"qwen2.5-lora-ne-en-local\", trust_remote_code=True)\n",
    "# model = PeftModel.from_pretrained(base, \"qwen2.5-lora-ne-en-local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b430f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_translate(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c1a3eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Translate English to Nepali: How are you?\n",
      "Assistant: तपाईँ यस देखाउनुहुन्छ?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"User: Translate English to Nepali: How are you?\\nAssistant:\"\n",
    "print(simple_translate(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28952cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Translate Nepali to English: तपाई कस्तो हुनुहुन्छ\n",
      "Assistant: This is not a valid number\n"
     ]
    }
   ],
   "source": [
    "prompt = \"User: Translate Nepali to English: तपाई कस्तो हुनुहुन्छ\\nAssistant:\"\n",
    "print(simple_translate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea332d",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ac8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5bddb6ef7d4761b834be5c36fdb31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/2.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8cf2d4e4d14a25bd40a9e1916a523c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38854cb831644563b4e568a58927ad19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jingmingliu01/qwen2.5-lora-ne-en/commit/c16571973e99b4caec471de285709ced6fbefde1', commit_message='Upload tokenizer', commit_description='', oid='c16571973e99b4caec471de285709ced6fbefde1', pr_url=None, repo_url=RepoUrl('https://huggingface.co/jingmingliu01/qwen2.5-lora-ne-en', endpoint='https://huggingface.co', repo_type='model', repo_id='jingmingliu01/qwen2.5-lora-ne-en'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"jingmingliu01/qwen2.5-lora-ne-en\")\n",
    "tokenizer.push_to_hub(\"jingmingliu01/qwen2.5-lora-ne-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c38ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qwen2.5-lora-ne-en-local/tokenizer_config.json',\n",
       " 'qwen2.5-lora-ne-en-local/special_tokens_map.json',\n",
       " 'qwen2.5-lora-ne-en-local/vocab.json',\n",
       " 'qwen2.5-lora-ne-en-local/merges.txt',\n",
       " 'qwen2.5-lora-ne-en-local/added_tokens.json',\n",
       " 'qwen2.5-lora-ne-en-local/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"qwen2.5-lora-ne-en-local\")\n",
    "tokenizer.save_pretrained(\"qwen2.5-lora-ne-en-local\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env0)",
   "language": "python",
   "name": "env0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
