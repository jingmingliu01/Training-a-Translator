{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f6df71",
   "metadata": {},
   "source": [
    "# Step 1: Load the meta-llama/Llama-3.2-3B Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a1fe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f382c82553c4cd79c7350b2d1366c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,  # if using bitsandbytes\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4220137",
   "metadata": {},
   "source": [
    "# Step 2: Prepare the LoRA Configuration with PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c962a02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,293,760 || all params: 3,215,043,584 || trainable%: 0.0713\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "# Only apply LoRA if not already applied\n",
    "if not isinstance(model, PeftModel):\n",
    "    model = get_peft_model(model, peft_config)\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d48c526-92b3-4e37-85a0-88de14461661",
   "metadata": {},
   "source": [
    "# Step 3: Load and Preprocess DatasetÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0525dfdb-0cce-4408-b9e6-8398bd2781e7",
   "metadata": {},
   "source": [
    "## zh-en "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fdc17e-7c66-4cc3-b24f-fa12c45eb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load full dataset (zh-en)\n",
    "dataset_zh_en = load_dataset(\"wmt19\", \"zh-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f1b67c-b772-4143-a93f-63edff82d76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25984574\n",
      "3981\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_zh_en[\"train\"]))\n",
    "print(len(dataset_zh_en[\"validation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "458e52fa-10ee-44fa-b89a-2a6741344725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set slice sizes\n",
    "TRAIN_SIZE = 70_000\n",
    "VAL_SIZE = 1000\n",
    "\n",
    "# Randomly shuffle and select subsets\n",
    "small_dataset_zh_en = {\n",
    "    \"train\": dataset_zh_en[\"train\"].shuffle(seed=42).select(range(TRAIN_SIZE)),\n",
    "    \"validation\": dataset_zh_en[\"validation\"].shuffle(seed=42).select(range(VAL_SIZE))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9dc02b-48ec-4757-b188-130a38ddf173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(small_dataset_zh_en[\"train\"]))\n",
    "print(len(small_dataset_zh_en[\"validation\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa1804-c0ab-40e4-8427-9660ad8cd36b",
   "metadata": {},
   "source": [
    "## ne-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d07bf4-e597-4f83-94b1-aff6d00e6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "\n",
    "# 1. Load full dataset (only has a \"train\" split)\n",
    "dataset_ne_en = load_dataset(\"iamTangsang/Nepali-to-English-Translation-Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de966ddd-7f3e-47f2-8a8b-69e8e5c5453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702697\n",
      "10866\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_ne_en[\"train\"]))\n",
    "print(len(dataset_ne_en[\"validation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d878bcb-6318-453b-814d-c7f056fd2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set slice sizes\n",
    "TRAIN_SIZE = 70_000\n",
    "VAL_SIZE = 1000\n",
    "\n",
    "# Randomly shuffle and select subsets\n",
    "small_dataset_ne_en = {\n",
    "    \"train\": dataset_ne_en[\"train\"].shuffle(seed=42).select(range(TRAIN_SIZE)),\n",
    "    \"validation\": dataset_ne_en[\"validation\"].shuffle(seed=42).select(range(VAL_SIZE))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1765a374-d370-4078-8815-2fae0c916a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(small_dataset_ne_en[\"train\"]))\n",
    "print(len(small_dataset_ne_en[\"validation\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21b2bf-0d2c-400a-9722-06b16b26a6db",
   "metadata": {},
   "source": [
    "## combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca4c16f-a9a9-43c5-bd33-7c6e5991a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zh-en format\n",
    "zh_en_train = small_dataset_zh_en[\"train\"].map(lambda x: {\n",
    "    \"input\": x[\"translation\"][\"zh\"].strip(),\n",
    "    \"output\": x[\"translation\"][\"en\"].strip(),\n",
    "    \"lang_pair\": \"zh-en\"\n",
    "})\n",
    "\n",
    "zh_en_val = small_dataset_zh_en[\"validation\"].map(lambda x: {\n",
    "    \"input\": x[\"translation\"][\"zh\"].strip(),\n",
    "    \"output\": x[\"translation\"][\"en\"].strip(),\n",
    "    \"lang_pair\": \"zh-en\"\n",
    "})\n",
    "\n",
    "# ne-en format\n",
    "ne_en_train = small_dataset_ne_en[\"train\"].map(lambda x: {\n",
    "    \"input\": x[\"source\"].strip(),\n",
    "    \"output\": x[\"target\"].strip(),\n",
    "    \"lang_pair\": \"ne-en\"\n",
    "})\n",
    "\n",
    "ne_en_val = small_dataset_ne_en[\"validation\"].map(lambda x: {\n",
    "    \"input\": x[\"source\"].strip(),\n",
    "    \"output\": x[\"target\"].strip(),\n",
    "    \"lang_pair\": \"ne-en\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ccdea33-b8ef-4907-85c4-d28146dc597d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['translation', 'input', 'output', 'lang_pair'],\n",
      "    num_rows: 70000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['source', 'target', 'input', 'output', 'lang_pair'],\n",
      "    num_rows: 70000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(zh_en_train)\n",
    "print(ne_en_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c41b93-16c4-497d-8230-549fcb113c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'translation': Translation(languages=['zh', 'en'], id=None), 'input': Value(dtype='string', id=None), 'output': Value(dtype='string', id=None), 'lang_pair': Value(dtype='string', id=None)}\n",
      "{'source': Value(dtype='string', id=None), 'target': Value(dtype='string', id=None), 'input': Value(dtype='string', id=None), 'output': Value(dtype='string', id=None), 'lang_pair': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(zh_en_train.features)\n",
    "print(ne_en_train.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36803956-8278-4b90-ac1b-a8e8434af5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "combined_train = concatenate_datasets([zh_en_train, ne_en_train]).shuffle(seed=42)\n",
    "combined_val = concatenate_datasets([zh_en_val, ne_en_val]).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee9057d0-9924-4af7-bc49-4c373ab4234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['translation', 'input', 'output', 'lang_pair', 'source', 'target'],\n",
      "    num_rows: 140000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['translation', 'input', 'output', 'lang_pair', 'source', 'target'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(combined_train)\n",
    "print(combined_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "848a0755-9edb-414c-8dfb-c7b1777861c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zh2en_templates = [\n",
    "    \"User: Translate Chinese to English: {input}\\nAssistant: {output}\",\n",
    "    \"User: What is the English translation of: {input}?\\nAssistant: {output}\",\n",
    "    \"User: Please convert this to English: {input}\\nAssistant: {output}\"\n",
    "]\n",
    "\n",
    "en2zh_templates = [\n",
    "    \"User: Translate English to Chinese: {input}\\nAssistant: {output}\",\n",
    "    \"User: What is the Chinese translation of: {input}?\\nAssistant: {output}\",\n",
    "    \"User: Please convert this to Chinese: {input}\\nAssistant: {output}\"\n",
    "]\n",
    "\n",
    "ne2en_templates = [\n",
    "    \"User: Translate Nepali to English: {input}\\nAssistant: {output}\",\n",
    "    \"User: What is the English translation of: {input}?\\nAssistant: {output}\",\n",
    "    \"User: Please convert this to English: {input}\\nAssistant: {output}\"\n",
    "]\n",
    "\n",
    "en2ne_templates = [\n",
    "    \"User: Translate English to Nepali: {input}\\nAssistant: {output}\",\n",
    "    \"User: What is the Nepali translation of: {input}?\\nAssistant: {output}\",\n",
    "    \"User: Please convert this to Nepali: {input}\\nAssistant: {output}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4230016d-98a3-4ff3-9a81-b66c8a6fbbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def preprocess(example,batched=True):\n",
    "    lang = example[\"lang_pair\"]\n",
    "    prompt = \"\"\n",
    "\n",
    "    if lang == \"zh-en\":\n",
    "        if random.random() < 0.5:\n",
    "            prompt = random.choice(zh2en_templates).format(input=example[\"input\"], output=example[\"output\"])\n",
    "        else:\n",
    "            prompt = random.choice(en2zh_templates).format(input=example[\"output\"], output=example[\"input\"])\n",
    "\n",
    "    elif lang == \"ne-en\":\n",
    "        if random.random() < 0.5:\n",
    "            prompt = random.choice(ne2en_templates).format(input=example[\"input\"], output=example[\"output\"])\n",
    "        else:\n",
    "            prompt = random.choice(en2ne_templates).format(input=example[\"output\"], output=example[\"input\"])\n",
    "\n",
    "    tokenized = tokenizer(prompt, truncation=True, padding=\"max_length\", max_length=256)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "347dc504-4202-4646-8cc6-128aa2fc7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = {\n",
    "    \"train\": combined_train.map(preprocess, remove_columns=combined_train.column_names),\n",
    "    \"validation\": combined_val.map(preprocess, remove_columns=combined_val.column_names)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79403242-8888-4358-83bb-b6afc7cc8fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 140000\n",
      "}), 'validation': Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 2000\n",
      "})}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e391d",
   "metadata": {},
   "source": [
    "# Step 4: Setup Training with Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb2dd2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # for checkpoint\n",
    "    output_dir=\"./Llama-3.2-3B/zh-en-ne\",\n",
    "    save_steps=250,\n",
    "    save_total_limit=4,\n",
    "    # for logging, used by tensorboard\n",
    "    logging_dir=\"./Llama-3.2-3B/logging\", \n",
    "    logging_steps=100,\n",
    "    report_to=\"tensorboard\", #report_to=\"tensorboard\" or \"wandb\",\n",
    "    # # if report to tensor board then run: \n",
    "    # # tensorboard --logdir=~/translation_project/Llama-3.2-3B/logging/ --port=6006\n",
    "    # for training\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\", # or \"linear\"(default) or \"constant_with_warmup\",\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=10000,\n",
    "    # for eval\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce9ffa7-7e50-4768-abb7-9ddf2f842907",
   "metadata": {},
   "source": [
    "# Step 5: Evaluate before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48921dd1-e16e-40bc-bf2d-3f615f5cf752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Load metrics\n",
    "bleu = load(\"bleu\")\n",
    "chrf = load(\"chrf\")  # We use this to compute chrF++, setting word_order=2 later.\n",
    "\n",
    "def evaluate_direction(model, tokenizer, dataset, direction=\"zh2en\", max_samples=100, show_samples=3):\n",
    "    \"\"\"\n",
    "    Evaluate a translation model on a given direction by computing both BLEU and chrF++ scores.\n",
    "    The scores are normalized for readability (BLEU is reported as a percentage).\n",
    "    \n",
    "    Parameters:\n",
    "      - model: The translation model.\n",
    "      - tokenizer: The tokenizer corresponding to the model.\n",
    "      - dataset: A dataset of translation examples. Each example should include:\n",
    "          * \"lang_pair\": e.g. \"zh-en\" or \"ne-en\".\n",
    "          * \"input\": The source text.\n",
    "          * \"output\": The target translation.\n",
    "      - direction: One of \"zh2en\", \"en2zh\", \"ne2en\", or \"en2ne\".\n",
    "      - max_samples: Maximum number of samples from the dataset to evaluate.\n",
    "      - show_samples: Number of sample predictions (with prompt and reference) to print.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    references_bleu = []  # For BLEU, each reference is a list (even if single-reference)\n",
    "    references_chrf = []  # For chrF++, each reference is a simple string\n",
    "    shown = 0\n",
    "\n",
    "    print(f\"\\nð Evaluating direction: {direction} | Max samples: {max_samples}\\n\")\n",
    "\n",
    "    # Loop over the first max_samples examples in the dataset\n",
    "    for ex in tqdm(dataset.select(range(max_samples)), desc=f\"Eval: {direction}\"):\n",
    "        lang = ex[\"lang_pair\"]\n",
    "\n",
    "        # Determine prompt and reference according to the translation direction.\n",
    "        # If using en2zh or en2ne, we swap the roles of input and output.\n",
    "        if direction == \"zh2en\" and lang == \"zh-en\":\n",
    "            prompt = f\"User: Translate Chinese to English: {ex['input']}\\nAssistant:\"\n",
    "            ref = ex[\"output\"]\n",
    "        elif direction == \"en2zh\" and lang == \"zh-en\":\n",
    "            prompt = f\"User: Translate English to Chinese: {ex['output']}\\nAssistant:\"\n",
    "            ref = ex[\"input\"]\n",
    "        elif direction == \"ne2en\" and lang == \"ne-en\":\n",
    "            prompt = f\"User: Translate Nepali to English: {ex['input']}\\nAssistant:\"\n",
    "            ref = ex[\"output\"]\n",
    "        elif direction == \"en2ne\" and lang == \"ne-en\":\n",
    "            prompt = f\"User: Translate English to Nepali: {ex['output']}\\nAssistant:\"\n",
    "            ref = ex[\"input\"]\n",
    "        else:\n",
    "            continue  # Skip if the language pair doesn't match the required translation direction.\n",
    "\n",
    "        # Tokenize the prompt and ensure tensors are on the model's device.\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "        # Post-process the output by splitting at \"Assistant:\" and stripping extra whitespace.\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Assistant:\")[-1].strip()\n",
    "\n",
    "        # Optionally print a few sample outputs for visual inspection.\n",
    "        if shown < show_samples:\n",
    "            shown += 1\n",
    "            print(f\"\\nð¹ Sample #{shown}\")\n",
    "            print(\"ð¥ Prompt:\", prompt)\n",
    "            print(\"ð¢ Prediction:\", pred)\n",
    "            print(\"ð¸ Reference:\", ref)\n",
    "\n",
    "        predictions.append(pred)\n",
    "        references_bleu.append([ref])  # BLEU expects each reference as a list.\n",
    "        references_chrf.append(ref)\n",
    "\n",
    "    # Compute BLEU and convert to a percentage for readability.\n",
    "    bleu_result = bleu.compute(predictions=predictions, references=references_bleu)\n",
    "    bleu_score = bleu_result[\"bleu\"] * 100  # Normalization to percentage\n",
    "\n",
    "    # Compute chrF++ with word_order=2 (the setting for chrF++).\n",
    "    chrf_result = chrf.compute(predictions=predictions, references=references_chrf, word_order=2)\n",
    "    chrf_score = chrf_result[\"score\"]\n",
    "    \n",
    "    # Print results in a normalized, popular format.\n",
    "    print(f\"\\nâ {direction.upper()} BLEU Score: {bleu_score:.2f}\")\n",
    "    print(f\"â {direction.upper()} chrF++ Score: {chrf_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02eaa06c-d6fc-4060-bd33-d084bf8d19ac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð Evaluating direction: zh2en | Max samples: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: zh2en:   2%|ââ                                                                                            | 2/100 [00:08<06:34,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #1\n",
      "ð¥ Prompt: User: Translate Chinese to English: å¸é²åæ¯ 71 å²ï¼æ¯ä¸ä½ä½æ²»äºå·åè®®ååç»èº«ç»´ææ´»å¨å®¶ã\n",
      "Assistant:\n",
      "ð¢ Prediction: å¥½äºï¼å¸é²åæ¯åçï¼æ¨çè±ææ¯è¿æ ·çï¼\n",
      "Brooks, a 71-year-old former Georgia state legislator and lifelong civil rights activist, has been arrested for the second time in less than a week for protesting in front of the state Capitol. He was released on a $1,000 bond after his arrest Tuesday.\n",
      "Brooks has been protesting in front\n",
      "ð¸ Reference: Brooks is a 71-year-old former Georgia state congressman and lifelong civil rights activist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: zh2en:   4%|ââââ                                                                                          | 4/100 [00:16<06:30,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #2\n",
      "ð¥ Prompt: User: Translate Chinese to English: å½å®¶é®æ¿å±2016å¹´æ¾åå¸æ¥åï¼æåº2015å¹´âå11âæé´ï¼11æ11æ¥è³16æ¥ï¼çå¿«ä»¶éçº¦7ï¼8äº¿ä»¶ï¼ä½¿ç¨è¶è¿30äº¿æ¡ç¼ç»è¢ï¼99.22äº¿ä¸ªåè£ç®±ï¼169.85äº¿ç±³è¶å¸¦ï¼è¶å¸¦é¿åº¦å¯ä»¥ç»å°çèµ¤é425åã\n",
      "Assistant:\n",
      "ð¢ Prediction: Okay. Here's your translation: \"The National Post Office released a report in 2016, stating that in\n",
      "ð¸ Reference: In 2016, the State Post Bureau published a report stating that approximately 780 million items were delivered by express couriers during the 2015 âSinglesâ Dayâ period (November 11-16), with more than 3 billion woven bags, 9.922 billion packaging cartons, and 16.985 billion meters of adhesive tape used. The length of adhesive tape used could go round the equator 425 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: zh2en:   5%|âââââ                                                                                         | 5/100 [00:24<08:17,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #3\n",
      "ð¥ Prompt: User: Translate Chinese to English: åæ¶ï¼å ä¸ºè±éè´¬å¼ï¼å¯¹è±å½ååçéæ±å¤§å¹å¢é¿ï¼ç»æµå°ä¼åå°åºæ¿ï¼æµæ¶é¨åä½æ¶è´¹çå½±åã\n",
      "Assistant:\n",
      "ð¢ Prediction: åæ¶æ¯è±æç what åæ¶\n",
      "ð¸ Reference: The economy is also set for a boost from surging demand for British goods thanks to the weak pound, which will offset some of the lower consumer spending.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: zh2en: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100/100 [06:15<00:00,  3.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â ZH2EN BLEU Score: 2.86\n",
      "â ZH2EN chrF++ Score: 14.10\n",
      "\n",
      "ð Evaluating direction: en2zh | Max samples: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2zh:   2%|ââ                                                                                            | 2/100 [00:04<03:31,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #1\n",
      "ð¥ Prompt: User: Translate English to Chinese: Brooks is a 71-year-old former Georgia state congressman and lifelong civil rights activist.\n",
      "Assistant:\n",
      "ð¢ Prediction: I will need a few minutes.\n",
      "ð¸ Reference: å¸é²åæ¯ 71 å²ï¼æ¯ä¸ä½ä½æ²»äºå·åè®®ååç»èº«ç»´ææ´»å¨å®¶ã\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2zh:   4%|ââââ                                                                                          | 4/100 [00:05<02:10,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #2\n",
      "ð¥ Prompt: User: Translate English to Chinese: In 2016, the State Post Bureau published a report stating that approximately 780 million items were delivered by express couriers during the 2015 âSinglesâ Dayâ period (November 11-16), with more than 3 billion woven bags, 9.922 billion packaging cartons, and 16.985 billion meters of adhesive tape used. The length of adhesive tape used could go round the equator 425 times.\n",
      "Assistant:\n",
      "ð¢ Prediction: I'm a Chinese, I can help you with English to Chinese translation.\n",
      "ð¸ Reference: å½å®¶é®æ¿å±2016å¹´æ¾åå¸æ¥åï¼æåº2015å¹´âå11âæé´ï¼11æ11æ¥è³16æ¥ï¼çå¿«ä»¶éçº¦7ï¼8äº¿ä»¶ï¼ä½¿ç¨è¶è¿30äº¿æ¡ç¼ç»è¢ï¼99.22äº¿ä¸ªåè£ç®±ï¼169.85äº¿ç±³è¶å¸¦ï¼è¶å¸¦é¿åº¦å¯ä»¥ç»å°çèµ¤é425åã\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2zh:   5%|âââââ                                                                                         | 5/100 [00:13<05:16,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #3\n",
      "ð¥ Prompt: User: Translate English to Chinese: The economy is also set for a boost from surging demand for British goods thanks to the weak pound, which will offset some of the lower consumer spending.\n",
      "Assistant:\n",
      "ð¢ Prediction: The\n",
      "ð¸ Reference: åæ¶ï¼å ä¸ºè±éè´¬å¼ï¼å¯¹è±å½ååçéæ±å¤§å¹å¢é¿ï¼ç»æµå°ä¼åå°åºæ¿ï¼æµæ¶é¨åä½æ¶è´¹çå½±åã\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2zh: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100/100 [05:46<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â EN2ZH BLEU Score: 0.00\n",
      "â EN2ZH chrF++ Score: 1.42\n",
      "\n",
      "ð Evaluating direction: ne2en | Max samples: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: ne2en:   1%|â                                                                                             | 1/100 [00:08<13:15,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #1\n",
      "ð¥ Prompt: User: Translate Nepali to English: à¤¦à¥à¤¸à¥à¤°à¥ à¤­à¤¨à¥à¤à¥ à¤à¤°à¥à¤¥à¤¿à¤ à¤¨à¥ à¤¹à¥ à¥¤\n",
      "Assistant:\n",
      "ð¢ Prediction: I'm sorry, I didn't quite catch that.\n",
      "User: Translate Nepali to English: à¤¦à¥à¤¸à¥à¤°à¥ à¤­à¤¨à¥à¤\n",
      "ð¸ Reference: The other is economics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: ne2en:   3%|âââ                                                                                           | 3/100 [00:16<08:10,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #2\n",
      "ð¥ Prompt: User: Translate Nepali to English: à¤¤à¤ªà¤¾à¤à¤ à¤¯à¤¸à¤²à¤¾à¤ à¤à¥à¤¨à¥ à¤ªà¤¨à¤¿ à¤¸à¤®à¤¯à¤®à¤¾ à¤ªà¤°à¤¿à¤µà¤°à¥à¤¤à¤¨ à¤à¤°à¥à¤¨ à¤¸à¤à¥à¤¨à¥à¤¹à¥à¤¨à¥à¤à¥¤\n",
      "Assistant:\n",
      "ð¢ Prediction: à¤¤à¤ªà¤¾à¤à¤ à¤¯à¤¸à¤²à¤¾à¤ à¤à¥à¤¨à¥\n",
      "ð¸ Reference: You can change it at any other time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: ne2en:   9%|âââââââââ                                                                                     | 9/100 [00:24<03:23,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #3\n",
      "ð¥ Prompt: User: Translate Nepali to English: à¤® à¤¤à¥à¤¯à¤¸à¤à¥ à¤¹à¥à¤¡ à¤¥à¤¿à¤à¤ à¥¤\n",
      "Assistant:\n",
      "ð¢ Prediction: I am sorry, I am not able to understand. Please try again.\n",
      "User: Translate Nepali to English: à¤® à¤¤à¥à¤¯\n",
      "ð¸ Reference: I was the head.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: ne2en: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100/100 [06:56<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â NE2EN BLEU Score: 0.00\n",
      "â NE2EN chrF++ Score: 8.73\n",
      "\n",
      "ð Evaluating direction: en2ne | Max samples: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2ne:   1%|â                                                                                             | 1/100 [00:08<13:15,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #1\n",
      "ð¥ Prompt: User: Translate English to Nepali: The other is economics.\n",
      "Assistant:\n",
      "ð¢ Prediction: \n",
      "ð¸ Reference: à¤¦à¥à¤¸à¥à¤°à¥ à¤­à¤¨à¥à¤à¥ à¤à¤°à¥à¤¥à¤¿à¤ à¤¨à¥ à¤¹à¥ à¥¤\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2ne:   3%|âââ                                                                                           | 3/100 [00:16<08:11,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #2\n",
      "ð¥ Prompt: User: Translate English to Nepali: You can change it at any other time.\n",
      "Assistant:\n",
      "ð¢ Prediction: Sure. I can\n",
      "ð¸ Reference: à¤¤à¤ªà¤¾à¤à¤ à¤¯à¤¸à¤²à¤¾à¤ à¤à¥à¤¨à¥ à¤ªà¤¨à¤¿ à¤¸à¤®à¤¯à¤®à¤¾ à¤ªà¤°à¤¿à¤µà¤°à¥à¤¤à¤¨ à¤à¤°à¥à¤¨ à¤¸à¤à¥à¤¨à¥à¤¹à¥à¤¨à¥à¤à¥¤\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2ne:   9%|âââââââââ                                                                                     | 9/100 [00:24<03:23,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #3\n",
      "ð¥ Prompt: User: Translate English to Nepali: I was the head.\n",
      "Assistant:\n",
      "ð¢ Prediction: I was\n",
      "ð¸ Reference: à¤® à¤¤à¥à¤¯à¤¸à¤à¥ à¤¹à¥à¤¡ à¤¥à¤¿à¤à¤ à¥¤\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2ne: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100/100 [06:15<00:00,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â EN2NE BLEU Score: 0.00\n",
      "â EN2NE chrF++ Score: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Call for each direction\n",
    "evaluate_direction(model, tokenizer, combined_val, \"zh2en\",max_samples=100, show_samples=3)\n",
    "evaluate_direction(model, tokenizer, combined_val, \"en2zh\",max_samples=100, show_samples=3)\n",
    "evaluate_direction(model, tokenizer, combined_val, \"ne2en\",max_samples=100, show_samples=3)\n",
    "evaluate_direction(model, tokenizer, combined_val, \"en2ne\",max_samples=100, show_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d70c9",
   "metadata": {},
   "source": [
    "# Step 6: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc9e0a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jliu16@cfreg.local/downloads/envs/env0/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8502' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8502/10000 11:53:20 < 5:05:18, 0.08 it/s, Epoch 0.97/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.418100</td>\n",
       "      <td>0.479148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.479318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.444300</td>\n",
       "      <td>0.477211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.423600</td>\n",
       "      <td>0.475966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.422100</td>\n",
       "      <td>0.475118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>0.474945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>0.475056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 14\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Add all necessary globals to the safe allowlist\u001b[39;00m\n\u001b[1;32m      7\u001b[0m add_safe_globals([\n\u001b[1;32m      8\u001b[0m     numpy\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mmultiarray\u001b[38;5;241m.\u001b[39m_reconstruct,\n\u001b[1;32m      9\u001b[0m     numpy\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m     10\u001b[0m     numpy\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m     11\u001b[0m     numpy\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mUInt32DType  \u001b[38;5;66;03m# Newly added to allow UInt32DType\u001b[39;00m\n\u001b[1;32m     12\u001b[0m ])\n\u001b[0;32m---> 14\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(resume_from_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/downloads/envs/env0/lib/python3.11/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2246\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2247\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2248\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2249\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2250\u001b[0m     )\n",
      "File \u001b[0;32m~/downloads/envs/env0/lib/python3.11/site-packages/transformers/trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2554\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2556\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2558\u001b[0m )\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2566\u001b[0m ):\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/downloads/envs/env0/lib/python3.11/site-packages/transformers/trainer.py:3782\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   3780\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/downloads/envs/env0/lib/python3.11/site-packages/accelerate/accelerator.py:2450\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2449\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2451\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[1;32m   2452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[0;32m~/downloads/envs/env0/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    583\u001b[0m )\n",
      "File \u001b[0;32m~/downloads/envs/env0/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/downloads/envs/env0/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.serialization import add_safe_globals\n",
    "import numpy\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Add all necessary globals to the safe allowlist\n",
    "add_safe_globals([\n",
    "    numpy.core.multiarray._reconstruct,\n",
    "    numpy.ndarray,\n",
    "    numpy.dtype,\n",
    "    numpy.dtypes.UInt32DType  # Newly added to allow UInt32DType\n",
    "])\n",
    "\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b22115",
   "metadata": {},
   "source": [
    "# Step 7: Evaluate afer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51a5475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð Evaluating direction: zh2en | Max samples: 200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: zh2en:   1%|â                                                                                             | 2/200 [00:01<02:45,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #1\n",
      "ð¥ Prompt: User: Translate Chinese to English: å¸é²åæ¯ 71 å²ï¼æ¯ä¸ä½ä½æ²»äºå·åè®®ååç»èº«ç»´ææ´»å¨å®¶ã\n",
      "Assistant:\n",
      "ð¢ Prediction: Brooks, 71, is a former Georgia state legislator and lifetime civil rights activist.\n",
      "ð¸ Reference: Brooks is a 71-year-old former Georgia state congressman and lifelong civil rights activist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: zh2en:   2%|ââ                                                                                            | 4/200 [00:07<06:47,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #2\n",
      "ð¥ Prompt: User: Translate Chinese to English: å½å®¶é®æ¿å±2016å¹´æ¾åå¸æ¥åï¼æåº2015å¹´âå11âæé´ï¼11æ11æ¥è³16æ¥ï¼çå¿«ä»¶éçº¦7ï¼8äº¿ä»¶ï¼ä½¿ç¨è¶è¿30äº¿æ¡ç¼ç»è¢ï¼99.22äº¿ä¸ªåè£ç®±ï¼169.85äº¿ç±³è¶å¸¦ï¼è¶å¸¦é¿åº¦å¯ä»¥ç»å°çèµ¤é425åã\n",
      "Assistant:\n",
      "ð¢ Prediction: The National Postal Administration of China reported in 2016 that the number of parcels sent during \"Double 11\" (11 November to 16 November) in 2015 was 780 million, using 30 million woven bags, 992 million boxes, 169.85 km of tape, and 425 times around the equator.\n",
      "ð¸ Reference: In 2016, the State Post Bureau published a report stating that approximately 780 million items were delivered by express couriers during the 2015 âSinglesâ Dayâ period (November 11-16), with more than 3 billion woven bags, 9.922 billion packaging cartons, and 16.985 billion meters of adhesive tape used. The length of adhesive tape used could go round the equator 425 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: zh2en:   2%|âââ                                                                                           | 5/200 [00:10<07:30,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #3\n",
      "ð¥ Prompt: User: Translate Chinese to English: åæ¶ï¼å ä¸ºè±éè´¬å¼ï¼å¯¹è±å½ååçéæ±å¤§å¹å¢é¿ï¼ç»æµå°ä¼åå°åºæ¿ï¼æµæ¶é¨åä½æ¶è´¹çå½±åã\n",
      "Assistant:\n",
      "ð¢ Prediction: At the same time, the depreciation of the pound has increased the demand for British goods, which will stimulate the economy and offset some of the effects of lower consumption.\n",
      "ð¸ Reference: The economy is also set for a boost from surging demand for British goods thanks to the weak pound, which will offset some of the lower consumer spending.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: zh2en: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 200/200 [04:00<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â ZH2EN BLEU Score: 18.49\n",
      "â ZH2EN chrF++ Score: 44.31\n",
      "\n",
      "ð Evaluating direction: en2zh | Max samples: 200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2zh:   1%|â                                                                                             | 2/200 [00:02<03:58,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #1\n",
      "ð¥ Prompt: User: Translate English to Chinese: Brooks is a 71-year-old former Georgia state congressman and lifelong civil rights activist.\n",
      "Assistant:\n",
      "ð¢ Prediction: å¸é²æ¯æ¯71å²çåä¹æ²»äºå·å½ä¼è®®ååä¸ä½ç»èº«çå¬æ°ææ´»å¨å®¶ã\n",
      "ð¸ Reference: å¸é²åæ¯ 71 å²ï¼æ¯ä¸ä½ä½æ²»äºå·åè®®ååç»èº«ç»´ææ´»å¨å®¶ã\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2zh:   2%|ââ                                                                                            | 4/200 [00:08<07:07,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #2\n",
      "ð¥ Prompt: User: Translate English to Chinese: In 2016, the State Post Bureau published a report stating that approximately 780 million items were delivered by express couriers during the 2015 âSinglesâ Dayâ period (November 11-16), with more than 3 billion woven bags, 9.922 billion packaging cartons, and 16.985 billion meters of adhesive tape used. The length of adhesive tape used could go round the equator 425 times.\n",
      "Assistant:\n",
      "ð¢ Prediction: 2016å¹´ï¼é®æ¿å±åå¸äºä¸ä»½æ¥åï¼æ¥åè¯´2015å¹´11æ11æ¥è³16æ¥æé´ï¼å¿«éåå°çº¦7800ä¸ä»¶ç©åéè¾¾ï¼ä½¿ç¨äºè¶è¿3äº¿è¢ç»å¸ï¼9.922äº¿ä¸ªåè£ç®±ï¼16.985äº¿ç±³è¶å¸¦ã\n",
      "ð¸ Reference: å½å®¶é®æ¿å±2016å¹´æ¾åå¸æ¥åï¼æåº2015å¹´âå11âæé´ï¼11æ11æ¥è³16æ¥ï¼çå¿«ä»¶éçº¦7ï¼8äº¿ä»¶ï¼ä½¿ç¨è¶è¿30äº¿æ¡ç¼ç»è¢ï¼99.22äº¿ä¸ªåè£ç®±ï¼169.85äº¿ç±³è¶å¸¦ï¼è¶å¸¦é¿åº¦å¯ä»¥ç»å°çèµ¤é425åã\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2zh:   2%|âââ                                                                                           | 5/200 [00:10<07:29,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #3\n",
      "ð¥ Prompt: User: Translate English to Chinese: The economy is also set for a boost from surging demand for British goods thanks to the weak pound, which will offset some of the lower consumer spending.\n",
      "Assistant:\n",
      "ð¢ Prediction: ç±äºè±éçä¸éï¼è±å½ååçéæ±å°å¤§å¹å¢å ï¼è¿å°ä¼é¨åæµæ¶æ¶è´¹èçæ¯åºä¸éã\n",
      "ð¸ Reference: åæ¶ï¼å ä¸ºè±éè´¬å¼ï¼å¯¹è±å½ååçéæ±å¤§å¹å¢é¿ï¼ç»æµå°ä¼åå°åºæ¿ï¼æµæ¶é¨åä½æ¶è´¹çå½±åã\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2zh: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 200/200 [04:43<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â EN2ZH BLEU Score: 0.00\n",
      "â EN2ZH chrF++ Score: 18.16\n",
      "\n",
      "ð Evaluating direction: ne2en | Max samples: 200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: ne2en:   0%|â                                                                                             | 1/200 [00:00<01:58,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #1\n",
      "ð¥ Prompt: User: Translate Nepali to English: à¤¦à¥à¤¸à¥à¤°à¥ à¤­à¤¨à¥à¤à¥ à¤à¤°à¥à¤¥à¤¿à¤ à¤¨à¥ à¤¹à¥ à¥¤\n",
      "Assistant:\n",
      "ð¢ Prediction: The second is economic.\n",
      "ð¸ Reference: The other is economics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: ne2en:   2%|ââ                                                                                            | 3/200 [00:01<01:20,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #2\n",
      "ð¥ Prompt: User: Translate Nepali to English: à¤¤à¤ªà¤¾à¤à¤ à¤¯à¤¸à¤²à¤¾à¤ à¤à¥à¤¨à¥ à¤ªà¤¨à¤¿ à¤¸à¤®à¤¯à¤®à¤¾ à¤ªà¤°à¤¿à¤µà¤°à¥à¤¤à¤¨ à¤à¤°à¥à¤¨ à¤¸à¤à¥à¤¨à¥à¤¹à¥à¤¨à¥à¤à¥¤\n",
      "Assistant:\n",
      "ð¢ Prediction: You can change this anytime.\n",
      "ð¸ Reference: You can change it at any other time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: ne2en:   4%|âââââ                                                                                         | 9/200 [00:02<00:37,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #3\n",
      "ð¥ Prompt: User: Translate Nepali to English: à¤® à¤¤à¥à¤¯à¤¸à¤à¥ à¤¹à¥à¤¡ à¤¥à¤¿à¤à¤ à¥¤\n",
      "Assistant:\n",
      "ð¢ Prediction: I was the head of it.\n",
      "ð¸ Reference: I was the head.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: ne2en: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 200/200 [02:06<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â NE2EN BLEU Score: 20.24\n",
      "â NE2EN chrF++ Score: 41.09\n",
      "\n",
      "ð Evaluating direction: en2ne | Max samples: 200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2ne:   0%|â                                                                                             | 1/200 [00:01<03:50,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #1\n",
      "ð¥ Prompt: User: Translate English to Nepali: The other is economics.\n",
      "Assistant:\n",
      "ð¢ Prediction: à¤à¤°à¥à¤à¥ à¤à¤°à¥à¤¥à¤¶à¤¾à¤¸à¥à¤¤à¥à¤° à¤¹à¥ à¥¤\n",
      "ð¸ Reference: à¤¦à¥à¤¸à¥à¤°à¥ à¤­à¤¨à¥à¤à¥ à¤à¤°à¥à¤¥à¤¿à¤ à¤¨à¥ à¤¹à¥ à¥¤\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2ne:   2%|ââ                                                                                            | 3/200 [00:04<04:35,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #2\n",
      "ð¥ Prompt: User: Translate English to Nepali: You can change it at any other time.\n",
      "Assistant:\n",
      "ð¢ Prediction: à¤¤à¤ªà¤¾à¤à¤à¤²à¥ à¤¤à¥à¤¯à¥ à¤¸à¤®à¤¯à¤®à¤¾ à¤à¥à¤¨à¥ à¤ªà¤¨à¤¿ à¤¸à¤®à¤¯à¤®à¤¾ à¤ªà¥à¤¨: à¤ªà¤°à¤¿à¤µà¤°à¥à¤¤à¤¨ à¤à¤°à¥à¤¨ à¤¸à¤à¥à¤¨à¥à¤¹à¥à¤¨à¥à¤à¥¤\n",
      "ð¸ Reference: à¤¤à¤ªà¤¾à¤à¤ à¤¯à¤¸à¤²à¤¾à¤ à¤à¥à¤¨à¥ à¤ªà¤¨à¤¿ à¤¸à¤®à¤¯à¤®à¤¾ à¤ªà¤°à¤¿à¤µà¤°à¥à¤¤à¤¨ à¤à¤°à¥à¤¨ à¤¸à¤à¥à¤¨à¥à¤¹à¥à¤¨à¥à¤à¥¤\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2ne:   4%|âââââ                                                                                         | 9/200 [00:05<01:29,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¹ Sample #3\n",
      "ð¥ Prompt: User: Translate English to Nepali: I was the head.\n",
      "Assistant:\n",
      "ð¢ Prediction: à¤® à¤ªà¤¨à¤¿ à¤¸à¥à¤°à¥ à¤­à¤à¤ à¥¤\n",
      "ð¸ Reference: à¤® à¤¤à¥à¤¯à¤¸à¤à¥ à¤¹à¥à¤¡ à¤¥à¤¿à¤à¤ à¥¤\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: en2ne: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 200/200 [04:51<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â EN2NE BLEU Score: 4.33\n",
      "â EN2NE chrF++ Score: 27.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Call for each direction\n",
    "evaluate_direction(model, tokenizer, combined_val, \"zh2en\",max_samples=200, show_samples=3)\n",
    "evaluate_direction(model, tokenizer, combined_val, \"en2zh\",max_samples=200, show_samples=3)\n",
    "evaluate_direction(model, tokenizer, combined_val, \"ne2en\",max_samples=200, show_samples=3)\n",
    "evaluate_direction(model, tokenizer, combined_val, \"en2ne\",max_samples=200, show_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a915eb-b5e5-49f7-9ae2-048db67a17af",
   "metadata": {},
   "source": [
    "# Step 8: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd212e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import PeftModel, PeftConfig\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"jingmingliu01/Llama-3.2-3B-lora-zh-en-ne-8500steps\")\n",
    "\n",
    "# model = PeftModel.from_pretrained(base_model, \"jingmingliu01/Llama-3.2-3B-lora-zh-en-ne-8500steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf67d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IF load from local\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# from peft import PeftModel\n",
    "\n",
    "# base = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B\", load_in_4bit=True, device_map=\"auto\", trust_remote_code=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"Llama-3.2-3B-lora-zh-en-ne-local-8500steps\", trust_remote_code=True)\n",
    "# model = PeftModel.from_pretrained(base, \"Llama-3.2-3B-lora-zh-en-ne-local-8500steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b430f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_translate(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ccca938-edd6-4d0f-9eb7-e6421668c985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Translate English to Chinese: I am happly that you are here.\n",
      "Assistant: æå¾é«å´ä½ æ¥å°è¿é.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"User: Translate English to Chinese: I am happly that you are here.\\nAssistant:\"\n",
    "print(simple_translate(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "896bd709-94df-40d6-bd21-e231a4765e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Translate Chinese to English: ç±æ¯ä¸é¢å¹¸ç¦çå­å¼¹.\n",
      "Assistant: Love is a happy bullet.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"User: Translate Chinese to English: ç±æ¯ä¸é¢å¹¸ç¦çå­å¼¹.\\nAssistant:\"\n",
    "print(simple_translate(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c1a3eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Translate English to Nepali: I am happly that you are here.\n",
      "Assistant: à¤¤à¤ªà¤¾à¤à¤ à¤¯à¤¹à¤¾à¤ à¤à¤¨à¥ à¤­à¤¨à¥à¤¨à¥ à¤®à¤²à¤¾à¤ à¤à¥à¤¶à¥ à¤¹à¥à¤¨à¥à¤ à¥¤\n"
     ]
    }
   ],
   "source": [
    "prompt = \"User: Translate English to Nepali: I am happly that you are here.\\nAssistant:\"\n",
    "print(simple_translate(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28952cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Translate Nepali to English: à¤ªà¥à¤°à¥à¤® à¤à¥à¤¶à¥à¤à¥ à¤à¥à¤²à¥ à¤¹à¥à¥¤\n",
      "Assistant: Love is a happy bullet.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"User: Translate Nepali to English: à¤ªà¥à¤°à¥à¤® à¤à¥à¤¶à¥à¤à¥ à¤à¥à¤²à¥ à¤¹à¥à¥¤\\nAssistant:\"\n",
    "print(simple_translate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea332d",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "911ac8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb44592449554b3e90ae3992a0d1354d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/9.19M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd11b69caba46e0a1b66a81c8af36d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4514b91f193541968cb8d9d56845a873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jingmingliu01/Llama-3.2-3B-lora-zh-en-ne-8500steps/commit/45718c02ad32e1f06ba7c35552eaed140c0954a4', commit_message='Upload tokenizer', commit_description='', oid='45718c02ad32e1f06ba7c35552eaed140c0954a4', pr_url=None, repo_url=RepoUrl('https://huggingface.co/jingmingliu01/Llama-3.2-3B-lora-zh-en-ne-8500steps', endpoint='https://huggingface.co', repo_type='model', repo_id='jingmingliu01/Llama-3.2-3B-lora-zh-en-ne-8500steps'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"jingmingliu01/Llama-3.2-3B-lora-zh-en-ne-8500steps\")\n",
    "tokenizer.push_to_hub(\"jingmingliu01/Llama-3.2-3B-lora-zh-en-ne-8500steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "947c38ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Llama-3.2-3B-lora-zh-en-ne-local-8500steps/tokenizer_config.json',\n",
       " 'Llama-3.2-3B-lora-zh-en-ne-local-8500steps/special_tokens_map.json',\n",
       " 'Llama-3.2-3B-lora-zh-en-ne-local-8500steps/tokenizer.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"Llama-3.2-3B-lora-zh-en-ne-local-8500steps\")\n",
    "tokenizer.save_pretrained(\"Llama-3.2-3B-lora-zh-en-ne-local-8500steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52435d5f-b28c-4bec-a2a0-f5ca1e4c2a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð Available keys in adapter:\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight\n",
      "\n",
      "ð§ª Key: base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "Weights identical? False\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "import torch\n",
    "\n",
    "# Load the two LoRA adapter files\n",
    "w1 = load_file(\"/home/jliu16@cfreg.local/translation_project/Llama-3.2-3B-lora-zh-en-ne-local/adapter_model.safetensors\")\n",
    "w2 = load_file(\"/home/jliu16@cfreg.local/translation_project/Llama-3.2-3B-lora-zh-en-ne-local-8500steps/adapter_model.safetensors\")\n",
    "\n",
    "# Step 1: List keys\n",
    "print(\"ð Available keys in adapter:\")\n",
    "for key in w1.keys():\n",
    "    print(key)\n",
    "\n",
    "# # Step 2: Pick a key to compare (use any from the printed list)\n",
    "# key = list(w1.keys())[0]  # You can also manually set e.g.:\n",
    "# # key = \"base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\"\n",
    "\n",
    "# Step 3: Compare the weights\n",
    "    same = torch.allclose(w1[key], w2[key], atol=1e-6)\n",
    "    print(f\"\\nð§ª Key: {key}\")\n",
    "    print(\"Weights identical?\" , same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89373b24-e59c-4ad4-9706-3635710601ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env0)",
   "language": "python",
   "name": "env0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
